{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Наивная-модель-(константное-значение)\" data-toc-modified-id=\"Наивная-модель-(константное-значение)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Наивная модель (константное значение)</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Catboost-classifier\" data-toc-modified-id=\"Catboost-classifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Catboost classifier</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Полносвязная-нейронная-сеть\" data-toc-modified-id=\"Полносвязная-нейронная-сеть-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Полносвязная нейронная сеть</a></span></li></ul></li><li><span><a href=\"#Тестирование-лучшей-модели\" data-toc-modified-id=\"Тестирование-лучшей-модели-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование лучшей модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Итоги\" data-toc-modified-id=\"Итоги-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Итоги</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, AutoModel\n",
    "from tqdm import notebook\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "except:\n",
    "    df = pd.read_csv('./toxic_comments.csv', index_col=0)\n",
    "df.info()\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликаты отсутствуют"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Распределение целевого класса\")\n",
    "plt.ylabel(\"Доля от общего количества\")\n",
    "plt.bar(['no_toxic','toxic'], [1 - df['toxic'].sum() / len(df), df['toxic'].sum() / len(df)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеет место дисбаланс целевого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('features.pickle', 'rb') as f:\n",
    "        embeddings = pickle.load(f)\n",
    "except:\n",
    "    tokenizer = BertTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "    model = AutoModel.from_pretrained('unitary/toxic-bert').to(device)\n",
    "    tokenized = df['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, padding = 'max_length', truncation=True))\n",
    "    tokenized = np.array([i for i in tokenized.values])\n",
    "    display(tokenized.shape)\n",
    "    attention_mask = np.where(tokenized != 0, 1, 0)\n",
    "    batch_size = 100\n",
    "    mod = tokenized.shape[0] % batch_size\n",
    "    embeddings = []\n",
    "    for i in notebook.tqdm(range(tokenized.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(tokenized[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "\n",
    "    batch = torch.LongTensor(tokenized[tokenized.shape[0] - mod:]).cuda()\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[tokenized.shape[0] - mod:]).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features.pickle', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features,\n",
    "    target,\n",
    "    stratify=target,\n",
    "    random_state = 42,\n",
    "    test_size=0.4\n",
    ")\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_valid,\n",
    "    target_valid,\n",
    "    stratify=target_valid,\n",
    "    random_state = 42,\n",
    "    test_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наивная модель (константное значение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyClassifier(strategy = 'constant', constant = 1)\n",
    "model.fit(features_train, target_train)\n",
    "preds = model.predict(features_test)\n",
    "accuracy_score(target_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state = 42)\n",
    "model.fit(features_train, target_train)\n",
    "preds = model.predict(features_valid)\n",
    "f'F1_valid = {f1_score(target_valid, preds)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dataset = Pool(data=features_train,\n",
    "                  label=target_train)\n",
    "\n",
    "model = CatBoostClassifier(iterations=1000,\n",
    "                           depth=5,\n",
    "                           learning_rate=0.01,\n",
    "                           verbose=100,\n",
    "                           eval_metric = \"TotalF1\"\n",
    "                          )\n",
    "model.fit(cv_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(features_valid)\n",
    "f1_score(target_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state = 42, class_weight='balanced')\n",
    "\n",
    "grid_space={'max_depth':[3,5,10],\n",
    "              'n_estimators':[50]\n",
    "           }\n",
    "grid = GridSearchCV(model,param_grid=grid_space,cv=4,scoring='f1', verbose=2, n_jobs=-1)\n",
    "model_grid = grid.fit(np.concatenate([features_train, features_valid]), np.concatenate([target_train, target_valid]))\n",
    "display(f'Best hyperparameters are: {model_grid.best_params_}')\n",
    "display(f'Best estimator is: {model_grid.best_estimator_}')\n",
    "display(f'Best score is: {model_grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полносвязная нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(64,64,64), learning_rate_init=0.001, max_iter=200, verbose=True, random_state = 42)\n",
    "model.fit(features_train, target_train)\n",
    "preds = model.predict(features_valid)\n",
    "f1_score(target_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state = 42)\n",
    "model.fit(features_train, target_train)\n",
    "preds = model.predict(features_test)\n",
    "f1_score(target_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате векторизации текстов с помощью BERT toxic получены эмбеддинги комментариев. Эмбеддинги использовались в качестве признаков при обучении логистической регрессии, случайного леса, модели catboost и полносвязной нейронной сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "\n",
    "- Загружен и проанализирован датасет из текстов комментариев, проанализирован дисбаланс целевого класса\n",
    "- Исходные тексты были переведены в пространство векторов токенизатором BERT и предобработанны моделью BERT, чтобы достичь лучшей связи между векторами\n",
    "- Обучены модели: логистическая регрессия, случайный лес, catboost, полносвязная нейронная сеть. Их метрика F1 составила 0.945, 0.944, 0.94, 0.935 соответственно. Все из них прошли проверку на адекватность.\n",
    "- По лучшему значению метрики F1 на валидационной выборке была выбрана модель - логистическая регрессия.\n",
    "- Лучшая модель была протестирована на тестовой выборке с результатом F1 = 0.943, что удовлетворяет условию задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Наивная-модель-(наиболее-часто-встречающееся-значение)\" data-toc-modified-id=\"Наивная-модель-(наиболее-часто-встречающееся-значение)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Наивная модель (наиболее часто встречающееся значение)</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Catboost-classifier\" data-toc-modified-id=\"Catboost-classifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Catboost classifier</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Полносвязная-нейронная-сеть\" data-toc-modified-id=\"Полносвязная-нейронная-сеть-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Полносвязная нейронная сеть</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Итоги\" data-toc-modified-id=\"Итоги-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Итоги</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 9433,
    "start_time": "2023-06-13T05:46:47.642Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-13T05:46:57.078Z"
   },
   {
    "duration": 3706,
    "start_time": "2023-06-13T05:46:57.084Z"
   },
   {
    "duration": 253,
    "start_time": "2023-06-13T05:47:00.792Z"
   },
   {
    "duration": 117,
    "start_time": "2023-06-13T05:47:01.047Z"
   },
   {
    "duration": 71705,
    "start_time": "2023-06-13T05:47:01.166Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:48:12.877Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:48:12.878Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:48:12.880Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:48:12.882Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:48:12.883Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:48:12.884Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:48:12.886Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:48:12.888Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:48:12.889Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:48:12.891Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-13T05:56:11.246Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-13T05:56:11.252Z"
   },
   {
    "duration": 891,
    "start_time": "2023-06-13T05:56:11.261Z"
   },
   {
    "duration": 230,
    "start_time": "2023-06-13T05:56:12.154Z"
   },
   {
    "duration": 111,
    "start_time": "2023-06-13T05:56:12.387Z"
   },
   {
    "duration": 23680,
    "start_time": "2023-06-13T05:56:12.501Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:56:36.183Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:56:36.184Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:56:36.186Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:56:36.187Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:56:36.188Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:56:36.189Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:56:36.191Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:56:36.192Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:56:36.193Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-13T05:56:36.194Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
